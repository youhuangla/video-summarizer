# 金字塔感知架构 (Pyramidal Perception Architecture)

本项目基于 [Video-Browser](https://github.com/chrisx599/Video-Browser) 论文提出的**金字塔感知架构**实现视频摘要生成。

## 核心思想

> **先粗后细，先定位后细化**

模仿人类观看视频的方式：
1. **快速浏览**（稀疏采样）→ 识别视频结构和章节边界
2. **仔细观看**（密集采样）→ 理解每个章节的具体内容

## 架构对比

### 传统单阶段方法

```
视频 → 均匀采样(每秒1帧) → VLM分析 → 输出

问题：
- 10分钟视频 = 600帧，超出VLM上下文限制
- 信息冗余，处理缓慢
- 无法平衡效率与质量
```

### 金字塔两阶段方法

```
┌─────────────────────────────────────────────────────────────┐
│                    Stage 1: 稀疏采样                         │
│                    (全局结构识别)                            │
├─────────────────────────────────────────────────────────────┤
│  视频                                                        │
│    │                                                         │
│    ▼                                                         │
│  均匀提取 N 帧 (默认8帧)                                      │
│    │                                                         │
│    ▼                                                         │
│  VLM分析: "视频有哪些章节？"                                  │
│    │                                                         │
│    ▼                                                         │
│  输出: 章节边界 [{start, end, title}] × M 个章节              │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    Stage 2: 密集采样                         │
│                    (局部内容细化)                            │
├─────────────────────────────────────────────────────────────┤
│  对每个章节分别处理:                                          │
│                                                              │
│  章节1  →  密集采样(0.1fps)  →  VLM分析  →  详细摘要          │
│  章节2  →  密集采样(0.1fps)  →  VLM分析  →  详细摘要          │
│  章节3  →  密集采样(0.1fps)  →  VLM分析  →  详细摘要          │
│                                                              │
│  输出: [{summary, key_quotes, visual_details, topics}]       │
└─────────────────────────────────────────────────────────────┘
```

## 技术细节

### Stage 1: 稀疏采样 (Sparse Sampling)

**目的**: 用最少的关键帧识别视频章节边界

**参数**:
- 采样数: `sparse_frame_count` (默认 8 帧)
- 采样方式: 均匀分布在整个视频时长

**计算**:
```
帧间隔 = 视频时长 / (采样数 - 1)

例如: 6分20秒视频, 8帧
帧间隔 = 380秒 / 7 ≈ 54秒
采样点: [0s, 54s, 108s, 163s, 217s, 271s, 326s, 380s]
```

**VLM 输入**:
- 8 张关键帧图片
- 字幕文本（前 8000 字符）
- 视频总时长

**VLM 输出**:
```json
{
  "chapters": [
    {"start": 0,   "end": 120,  "title": "开场介绍"},
    {"start": 115, "end": 270,  "title": "核心内容"},
    {"start": 265, "end": 380,  "title": "总结"}
  ]
}
```

### Stage 2: 密集采样 (Dense Sampling)

**目的**: 在已识别的章节内部生成详细摘要

**参数**:
- 采样率: `dense_fps` (默认 0.1 = 每10秒1帧)
- 采样范围: 单个章节的时间区间

**计算**:
```
帧数 = 章节时长 × dense_fps

例如: 150秒的章节, fps=0.1
帧数 = 150 × 0.1 = 15 帧
采样点: [120s, 130s, 140s, ..., 270s]
```

**VLM 输入**:
- 15 张章节内帧图片
- 章节对应字幕文本
- 章节标题提示

**VLM 输出**:
```json
{
  "summary": "本章详细介绍了...",
  "key_quotes": ["台词1", "台词2"],
  "visual_details": "画面展示了...",
  "topics": ["主题1", "主题2"]
}
```

## 优势分析

### 效率优势

| 指标 | 单阶段密集采样 | 金字塔两阶段 |
|------|---------------|-------------|
| 10分钟视频总帧数 | 600 帧 | 8 + 45 = 53 帧 |
| VLM 调用次数 | 1 次 (输入过多) | 1 + 3 = 4 次 (合理) |
| 处理时间 | 超时/失败 | ~50 秒 |
| 上下文限制 | 超出 | 符合 |

### 质量优势

1. **结构清晰**: Stage 1 确保章节边界准确
2. **内容完整**: Stage 2 确保每个章节有详细摘要
3. **可扩展性**: 支持任意长度视频（分段处理）

## 长视频处理

对于超过 10 分钟的视频，采用**分段 + 重叠**策略：

```
视频: 0━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━1800s (30分钟)

分段1: 0━━━━━━━━━━━━━━━━━━600s
       └─ 重叠 30s ─┘
分段2:          570━━━━━━━━━━━━━━━━━━1170s
                └─ 重叠 30s ─┘
分段3:                        1140━━━━━━━━━━━━━━━━━━1800s

每段独立应用金字塔架构:
- Stage 1: 8 帧定位章节
- Stage 2: 密集采样生成摘要

最后合并重叠区域的章节
```

## 配置参数

相关配置项 (`SummarizerConfig`):

```python
# Stage 1: 稀疏采样
sparse_frame_count: int = 8      # 章节检测帧数

# Stage 2: 密集采样  
dense_fps: float = 0.1           # 章节内采样率 (帧/秒)

# 长视频分段
segment_duration: int = 600      # 分段时长 (秒)
overlap_duration: int = 30       # 分段重叠 (秒)

# 章节约束
min_chapter_duration: int = 30   # 最短章节 (秒)
max_chapters: int = 6            # 最大章节数
```

## 总结

金字塔感知架构的核心价值：

> **用 53 帧完成原本需要 600 帧的工作，同时保持甚至提升摘要质量。**

这是通过**任务分解**实现的：
- Stage 1 解决"在哪里"（定位）
- Stage 2 解决"是什么"（理解）

两阶段各司其职，相互配合，最终实现高效、高质量的视频摘要生成。

## 参考

- [Video-Browser](https://github.com/chrisx599/Video-Browser) - 论文实现参考
- [decord](https://github.com/dmlc/decord) - 高效视频帧提取
